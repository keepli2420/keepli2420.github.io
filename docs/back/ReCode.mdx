---
description: 回顾
custom_edit_url: null
---

# 回顾

## JVM算法

Minor 复制算法
major 标记清除算法

引用计数法：如果一个对象的被引用次数为0，则说明这个对象可能不再会被用到，那么这个对象就是可回收的对象
存在循环引用问题

可达性分析：为了解决循环引用，以一系列的GCroot对象作为起点搜索，如果GC roots 和一个对象之间没有可达路径，这称该对象不可达，在经过两侧标记过程后，将面临回收

标记清除法：最基础的回收算法。分为两阶段，标记和清除。标记所有需要清除的对象，清除回收被标记的对象所占用的空间
存在内存碎片化问题，后续大对象找不到可利用的空间

复制算法：为了解决碎片化。将内存等分，每次只是用其中一个，当这块内存满后将存活对象复制到另外一块上去，其余的清除。这种算法实现简单，内存效率高，不易产生碎片
但是内存被压缩到了一半，且存活对象多的话，Copying算法的效率大大降低。

标记整理算法：结合以上两个算法而提出。标记后不是清理对象而是将存活的对象压缩到内存的一端，顺序排放，然后清除边界外的所有空间


分代收集算法：分代收集法是目前大部分 JVM 所采用的方法，根据对象存活的不同生命周期将内存
划分为不同的域，一般情况下将 GC 堆划分为老生代(Tenured/Old Generation)和新生代(Young
Generation)。老生代的特点是每次垃圾回收时只有少量对象需要被回收，新生代的特点是每次垃
圾回收时都有大量垃圾需要被回收，因此可以根据不同区域选择不同的算法

### GC 分代收集算法 VS 分区收集算法
当前主流 JVM 垃圾收集都采用”分代收集”(Generational Collection)算法, 这种算法会根据
对象存活周期的不同将内存划分为几块, 如 JVM 中的 新生代、老年代、永久代，这样就可以根据
各年代特点分别采用最适当的 GC 算法

#### 在新生代-复制算法
每次垃圾收集都能发现大批对象已死, 只有少量存活. 因此选用复制算法, 只需要付出少量
存活对象的复制成本就可以完成收集.

#### 在老年代-标记整理算法
因为对象存活率高、没有额外空间对它进行分配担保, 就必须采用“标记—清理”或“标
记—整理”算法来进行回收, 不必进行内存复制, 且直接腾出空闲内存.

### 分区收集算法
分区算法则将整个堆空间划分为连续的不同小区间, 每个小区间独立使用, 独立回收. 这样做的
好处是可以控制一次回收多少个小区间 , 根据目标停顿时间, 每次合理地回收若干个小区间(而不是
整个堆), 从而减少一次 GC 所产生的停顿。

## JAVA 四中引用类型

1. 在 Java 中最常见的就是强引用，把一个对象赋给一个引用变量，这个引用变量就是一个强引
用。当一个对象被强引用变量引用时，它处于可达状态，它是不可能被垃圾回收机制回收的，即
使该对象以后永远都不会被用到 JVM 也不会回收。因此强引用是造成 Java 内存泄漏的主要原因之
一。

2. 软引用需要用 SoftReference 类来实现，对于只有软引用的对象来说，当系统内存足够时它
不会被回收，当系统内存空间不足时它会被回收。软引用通常用在对内存敏感的程序中。

3. 弱引用需要用 WeakReference 类来实现，它比软引用的生存期更短，对于只有弱引用的对象
来说，只要垃圾回收机制一运行，不管 JVM 的内存空间是否足够，总会回收该对象占用的内存。


4. 虚引用需要 PhantomReference 类来实现，它不能单独使用，必须和引用队列联合使用。虚
引用的主要作用是跟踪对象被垃圾回收的状态。






## 类的加载机制
类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，
用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。

类的加载过程
1. 加载：将Java类的字节码文件加载到机器内存中，并在内存中构建出Java类的原型——类模板对象。
所谓类模板对象，其实就是Java类在JVM内存中的一个快照，JVM将从字节码文件中解析出的常量池、类字段、类方法等信息存储到类模板中，
这样JVM在运行期便能通过类模板而获取Java类中的任意信息，能够对Java类的成员变量进行遍历，也能进行Java方法的调用。
类模型的位置，加载的类在JVM中创建相应的类结构，类结构会存储在方法区(JDK1.8之前:永久代;JDK1.8及之后:元空间)。
一般来说加载分为以下几步：
(1) 通过一个类的全限定名获取此类的二进制字节流
(2) 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构
(3) 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口
2. 连接（验证，准备，解析） 
  * 验证：用于确保类或接口的二进制表示结构上是正确的，从而确保字节流包含的信息对虚拟机来说是安全的。
  * 准备：准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使
用的内存空间。
  * 解析：是指虚拟机将常量池中的符号引用替换为直接引用的过程。
3. 初始化：是执行类构造器方法的过程，类构造器方法私有编译器自动收集类中的类变量的赋值赋值操作
和静态语句块中的的语句合并而成的。
虚拟机会保证子构造器方法执行前，父构造器方法已经执行完毕。
如果一个类中没有对静态变量赋值也没有静态代码块，name编译器就可以不为这个类生成类构造器方法


## 类加载器
1. 启动类加载器（BootStrap ClassLoader）
负责加载 JAVA_HOME\lib 目录中的，或通过-Xbootclasspath 参数指定路径中的，且被
虚拟机认可（按文件名识别，如 rt.jar）的类。
2. 扩展类加载器（Extension ClassLoader）
负责加载 JAVA_HOME\lib\ext 目录中的，或通过 java.ext.dirs 系统变量指定路径中的类
库。
3. 应用程序加载器（Application ClassLoader）
负责加载用户路径（classpath）上的类库。

可以通过继承ClassLoader自定义类加载器

### 双亲委派模型
当一个类收到加载请求，它首先不会尝试自己加载这个类，而是委托给父类去加载，每一层类加载器都是如此。
因此每个加载请求都会请求到启动类加载器去加载。只有当父类加载器无法加载的时候才会被子类尝试加载、
这样确保了使用不同的类加载器最终加载的都是同一个类


## JAVA集合
集合类存放于 Java.util 包中，主要有 3 种：`set(集）`、`list(列表包含 Queue）`和 `map(映射)`。

* List
  * ArrayList（数组）：是通过数组实现，它允许对元素进行快速随机访问。当数组大小不满足时需要增加存储能力，就要将已经有数
组的数据复制到新的存储空间中。当从 ArrayList 的中间位置插入或者删除元素时，需要对数组进
行复制、移动代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。
  * Vector（数组实现、线程同步）：Vector 与 ArrayList 一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一
个线程能够写 Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，
访问它比访问 ArrayList 慢。
  * LinedkList（链表）：LinkedList 是用链表结构存储数据的，很适合数据的动态插入和删除，随机访问和遍历速度比较
慢。另外，他还提供了 List 接口中没有定义的方法，专门用于操作表头和表尾元素，可以当作堆
栈、队列和双向队列使用。
* Set
    存储无序，值不能重复对象的相等性本质是对象 hashCode 值（java 是依据对象的内存地址计算出的此序号）判断
的，如果想要让两个不同的对象视为相等的，就必须覆盖 Object 的 hashCode 方法和 equals 方
法。
  * HashSet（Hash 表）：哈希表边存放的是哈希值。HashSet 存储元素的顺序并不是按照存入时的顺序（和 List 显然不
同） 而是按照哈希值来存的所以取数据也是按照哈希值取得。元素的哈希值是通过元素的
hashcode 方法来获取的, HashSet 首先判断两个元素的哈希值，如果哈希值一样，接着会比较
equals 方法 如果 equls 结果为 true ，HashSet 就视为同一个元素。如果 equals 为 false 就不是
同一个元素。
HashSet 通过 hashCode 值来确定元素在内存中的位置。一个 hashCode 位置上可以存放多个元素。
  
  * TreeSet（二叉树）：TreeSet()是使用二叉树的原理对新 add()的对象按照指定的顺序排序（升序、降序），每增
加一个对象都会进行排序，将对象插入的二叉树指定的位置。Integer 和 String 对象都可以进行默认的 TreeSet 排序，而自定义类的对象是不可以的，自
己定义的类必须实现 Comparable 接口，并且覆写相应的 compareTo()函数，才可以正常使
用。在覆写 compare()函数时，要返回相应的值才能使 TreeSet 按照一定的规则来排序比较此对象与指定对象的顺序。如果该对象小于、等于或大于指定对象，则分别返回负整
数、零或正整数。
  * LinkHashSet（HashSet+LinkedHashMap）：对于 LinkedHashSet 而言，它继承与 HashSet、又基于 LinkedHashMap 来实现的。
LinkedHashSet 底层使用 LinkedHashMap 来保存所有元素，它继承与 HashSet，其所有的方法
操作上又与 HashSet 相同，因此 LinkedHashSet 的实现上非常简单，只提供了四个构造方法，并
通过传递一个标识参数，调用父类的构造器，底层构造一个 LinkedHashMap 来实现，在相关操
作上与父类 HashSet 的操作相同，直接调用父类 HashSet 的方法即可。
* Map
  * HashMap（数组+链表+红黑树）:HashMap 最多只允许一条记录的键为 null，允许多条记
录的值为 null。HashMap 非线程安全，即任一时刻可以有多个线程同时写 HashMap，可能会导
致数据的不一致。如果需要满足线程安全，可以用 Collections 的 synchronizedMap 方法使
HashMap 具有线程安全的能力，或者使用 ConcurrentHashMap。
<br/>
capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。初始16<br/>
loadFactor：负载因子，默认为 0.75。<br/>
threshold：扩容的阈值，等于 capacity * loadFactor<br/>
JAVA7实现：HashMap 里面是一个数组，然后数组中每个元素是一个单向链表
<br/>
JAVA8实现：是利用了红黑树，所以其由 数组+链表+红黑树 组成。当链表长度超过8时转换成红黑树
  * ConcurrentHashMap：ConcurrentHashMap 和 HashMap 思路是差不多的，但是因为它支持并发操作，所以要复杂一
些。整个 ConcurrentHashMap 由一个个 Segment 组成，Segment 代表”部分“或”一段“的
意思，所以很多地方都会将其描述为分段锁。
  * HashTable（线程安全）：是遗留类。不需要线程安全的场合可以用 HashMap 替换，需要线程安全的场合可以用 ConcurrentHashMap 替换。
  * TreeMap（可排序）：在使用 TreeMap 时，key 必须实现 Comparable 接口或者在构造 TreeMap 传入自定义的
Comparator，否则会在运行时抛出 java.lang.ClassCastException 类型的异常。
  * LinkedHashMap（记录插入顺序）： 是 HashMap 的一个子类，保存了记录的插入顺序，在用 Iterator 遍历
LinkedHashMap 时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。
内部维护了一个运行于所有条目的双重链接列表

## JAVA多线程并发
Thread 类本质上是实现了 Runnable 接口的一个实例，代表一个线程的实例。启动线程的唯一方
法就是通过 Thread 类的 start()实例方法。start()方法是一个 native 方法，它将启动一个新线程，
并执行 run()方法。


继承Thread、实现Runnable接口、实现Callable接口均可自定义线程类。

### 线程的生命周期（状态）
当线程被创建并启动以后，它既不是一启动就进入了执行状态，也不是一直处于执行状态。
在线程的生命周期中，它要经过新建(New)、就绪（Runnable）、运行（Running）、阻塞
(Blocked)和死亡(Dead)5 种状态。尤其是当线程启动以后，它不可能一直"霸占"着 CPU 独自
运行，所以 CPU 需要在多条线程之间切换，于是线程状态也会多次在运行、阻塞之间切换
1. 新建状态：使用 new 关键字创建了一个线程之后，该线程就处于新建状态，此时仅由 JVM 为其分配
内存，并初始化其成员变量的值
2. 就绪状态：当线程对象调用了 start()方法之后，该线程处于就绪状态。Java 虚拟机会为其创建方法调用栈和
程序计数器，等待调度运行。
3. 运行状态：如果处于就绪状态的线程获得了 CPU，开始执行 run()方法的线程执行体，则该线程处于运行状态。
4. 阻塞状态：阻塞状态是指线程因为某种原因放弃了 cpu 使用权，暂时停止运行。阻塞的情况分三种：
   1. 等待阻塞：运行的线程调用wait()方法，JVM会把线程放入等待队列中
   2. 同步阻塞：运行的线程在获取同步锁时。若该同步锁被别的线程占用，JVM会把线程放入锁池中。
   3. 其他阻塞：Thread.sleep()、t.join、I/O请求，当 sleep()状态超时、join()等待线程终止或者超时、
   或者 I/O、socket 中的 receiver,accept
处理完毕时，线程重新转入可运行(runnable)状态。
5. 线程死亡：
   1. 正常结束：run()或 call()方法执行完成，线程正常结束
   2. 异常结束：线程抛出一个未捕获的 Exception 或 Error。
   3. 调用stop：直接调用该线程的 stop()方法来结束该线程—该方法通常容易导致死锁，不推荐使用

### 线程基本方法
线程相关的基本方法有 wait，notify，notifyAll，sleep，join，yield 等。
1. wait()：调用该方法的线程进入 WAITING 状态，只有等待另外线程的通知或被中断才会返回，
需要注意的是调用 wait()方法后，会释放对象的锁。因此，wait 方法一般用在同步方法或同步代码块中。
2. sleep()：sleep 导致当前线程休眠，与 wait 方法不同的是 sleep 不会释放当前占有的锁,
sleep(long)会导致线程进入 TIMED-WATING 状态，而 wait()方法会导致当前线程进入 WATING 状态
3. yield()：yield 会使当前线程让出 CPU 执行时间片，与其他线程一起重新竞争 CPU 时间片。
4. interrupt()：中断一个线程，其本意是给这个线程一个通知信号，会影响这个线程内部的一个中断标识位。
这个线程本身并不会因此而改变状态(如阻塞，终止等)。若调用 sleep()而使线程处于 TIMED-WATING 状态，这时调用 interrupt()方法，
会抛出InterruptedException,从而使线程提前结束 TIMED-WATING 状态.抛出异常前，都会清除中断标识位，所以抛出异常后，
调用 isInterrupted()方法将会返回 false<br/>
<p>中断状态是线程固有的一个标识位，可以通过此标识位安全的终止线程。在线程的 run 方法内部可以根据 thread.isInterrupted()的值来优雅的终止线程。
</p>
5. Join()：join() 方法，等待其他线程终止，在当前线程中调用一个线程的 join() 方法，
则当前线程转为阻塞状态，回到另一个线程结束，当前线程再由阻塞状态变为就绪状态。
<p>很多情况下，主线程生成并启动了子线程，需要用到子线程返回的结果，也就是需要主线程需要在子线程结束后再结束，
    这时候就要用到 join() 方法。
</p>
6. notify()：随机唤醒一个等待线程
7. notifyAll()：唤醒所有等待线程
8. isAlive()： 判断一个线程是否存活。
9. activeCount()： 程序中活跃的线程数。
10. enumerate()： 枚举程序中的线程。
11. currentThread()： 得到当前线程。
12. setDaemon()： 设置一个线程为守护线程。(用户线程和守护线程的区别在于，是否等待主线程依赖于主线程结束而结束) 
13. setName()： 为线程设置一个名称。
14. setPriority()： 设置一个线程的优先级。

### 线程上下文切换
CPU 给每个任务都服务一定的时间，然后把当前任务的状态保存下来。然后加载下一任务的状态，继续服务下一任务。
任务的状态保存及再加载, 这段过程就叫做上下文切换。时间片轮转的方式使多个任务在同一颗 CPU 上执行变成了可能。

#### 进程
是指一个程序运行的实例。
#### 上下文
是指某一时间点 CPU 寄存器和程序计数器的内容。
#### 寄存器
是 CPU 内部的数量较少但是速度很快的内存
#### 程序计数器
是一个专用的寄存器，用于表明指令序列中 CPU 正在执行的位置，存的值为正在执行的指令的位置或者下一个将要被执行的指令的位置


### 线程池
线程和数据库连接这些资源都是非常宝贵的资源。那么每次需要的时候创建，不需要的时候销毁，是非常浪费资源的。
那么我们就可以使用缓存的策略，也就是使用线程池。

Java 里面线程池的顶级接口是 Executor，但是严格意义上讲 Executor 并不是一个线程池，而
只是一个执行线程的工具。真正的线程池接口是 ExecutorService。

#### 四种线程池
1. Executors.newCacheThreadPool()：可缓存线程池，先查看池中有没有以前建立的线程，如果有，就直接使用。
如果没有，就建一个新的线程加入池中，缓存型池子通常用于执行一些生存期很短的异步型任务
2. Executors.newFixedThreadPool(int n)：创建一个可重用固定个数的线程池，以共享的无界队列方式来运行这些线程。
定长线程池的大小最好根据系统资源进行设置。如Runtime.getRuntime().availableProcessors()
3. Executors.newScheduledThreadPool(int n)：创建一个定长线程池，支持定时及周期性任务执行
4. Executors.newSingleThreadExecutor()：创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，
保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

#### 自定义线程池
1. corePoolSize：指定了线程池中的线程数量。
2. maximumPoolSize：指定了线程池中的最大线程数量。
3. keepAliveTime：当前线程池数量超过 corePoolSize 时，多余的空闲线程的存活时间，即多
次时间内会被销毁。
4. unit：keepAliveTime 的单位。
5. workQueue：任务队列，被提交但尚未被执行的任务。
6. threadFactory：线程工厂，用于创建线程，一般用默认的即可。
7. handler：拒绝策略，当任务太多来不及处理，如何拒绝任务。

常见的构造函数：
```java
ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, 
                    TimeUnit unit, BlockingQueue<Runnable> workQueue)
```

#### 缓冲队列（BlockingQueue阻塞队列）
BlockingQueue是双缓冲队列。BlockingQueue内部使用两条队列，
允许两个线程同时向队列一个存储，一个取出操作。在保证并发安全的同时，提高了队列的存取效率。

1. ArrayBlockingQueue（int i）:规定大小的BlockingQueue，其构造必须指定大小。其所含的对象是FIFO顺序排序的。
2. LinkedBlockingQueue（）或者（int i）:大小不固定的BlockingQueue，若其构造时指定大小，生成的BlockingQueue有大小限制，
不指定大小，其大小有Integer.MAX_VALUE来决定。其所含的对象是FIFO顺序排序的。
3. PriorityBlockingQueue（）或者（int i）:类似于LinkedBlockingQueue，但是其所含对象的排序不是FIFO，
而是依据对象的自然顺序或者构造函数的Comparator决定。
4. SynchronizedQueue（）:特殊的BlockingQueue，对其的操作必须是放和取交替完成。不存储数据、可用于传递数据
5. DelayQueue：延迟队列。

### CyclicBarrier、CountDownLatch、Semaphore 的用法
1. CountDownLatch（线程计数器 ）
2. CyclicBarrier（回环栅栏-等待至 barrier 状态再全部同时执行）
3. Semaphore（信号量-控制同时访问的线程个数）

#### 拒绝策略
线程池中的线程已经用完了，无法继续为新任务服务，同时，等待队列也已经排满了，
再也塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。
1. AbortPolicy ： 直接抛出异常，阻止系统正常运行。
2. CallerRunsPolicy ： 只要线程池未关闭，该策略直接在调用者线程中运行，任务提交线程的性能极有可能会急剧下降。
3. DiscardOldestPolicy ： 丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。
4. DiscardPolicy ： 该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。
<p>以上内置拒绝策略均实现了 RejectedExecutionHandler 接口，若以上策略仍无法满足实际
需要，完全可以自己扩展 RejectedExecutionHandler 接口。</p>

### volatile 关键字的作用（变量可见性、禁止重排序）
Java 语言提供了一种稍弱的同步机制，即 volatile 变量，用来确保将变量的更新操作通知到其他
线程。volatile 变量具备两种特性，volatile 变量不会被缓存在寄存器或者对其他处理器不可见的
地方，因此在读取 volatile 类型的变量时总会返回最新写入的值。
#### 变量可见性
其一是保证该变量对所有线程可见，这里的可见性指的是当一个线程修改了变量的值，那么新的
值对于其他线程是可以立即获取的。

#### 禁止重排序
volatile 禁止了指令重排。

当对非 volatile 变量进行读写的时候，每个线程先从内存拷贝变量到 CPU 缓存中。如果计算机有
多个 CPU，每个线程可能在不同的 CPU 上被处理，这意味着每个线程可以拷贝到不同的 CPU
cache 中。而声明变量是 volatile 的，JVM 保证了每次读变量都从内存中读，跳过 CPU cache
这一步。



## 锁

### 悲观锁/乐观锁
乐观锁：顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，
但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制
在Java中java.util.concurrent.atomic包下面的
原子变量类就是使用了乐观锁的一种实现方式CAS(Compare and Swap 比较并交换)实现的。

悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，
这样别人想拿这个数据就会阻塞直到它拿到锁。比如Java里面的同步原语synchronized关键字的实现就是悲观锁。

悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。

乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。

#### CAS操作
CAS（Compare and Swap 比较并交换）当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，
而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。

CAS操作中包含三个操作数——需要读写的内存位置(V)、进行比较的预期原值(A)和拟写入的新值(B)。
如果内存位置V的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值B，否则处理器不做任何操作


### 独享锁/共享锁
独享锁是指该锁一次只能被一个线程所持有。

共享锁是指该锁可被多个线程所持有。

对于Java ReentrantLock而言，其是独享锁。但是对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。


### 互斥锁/读写锁
上面讲的独享锁/共享锁就是一种广义的说法，互斥锁/读写锁就是具体的实现。

互斥锁在Java中的具体实现就是ReentrantLock。

读写锁在Java中的具体实现就是ReadWriteLock。

### 可重入锁
可重入锁就是一个线程不用释放，可以重复的获取一个锁n次，只是在释放的时候，也需要相应的释放n次。

### 公平锁/非公平锁
公平锁是指多个线程按照申请锁的顺序来获取锁。

非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。

对于Java ReetrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。

对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。

### 分段锁

分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。

分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。

### 偏向锁/轻量级锁/重量级锁
这三种锁是指锁的状态，并且是针对Synchronized。在Java 5通过引入锁升级的机制来实现高效Synchronized。
这三种锁的状态是通过对象监视器在对象头中的字段来表明的。

偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。

轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。

重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，
就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让他申请的线程进入阻塞，性能降低。


### 自旋锁
在Java中，自旋锁是指尝试获取锁的线程不会立即阻塞，
而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。


### 锁优化
1. 减少锁持有时间：只用在有线程安全要求的程序上加锁
2. 适当减小锁粒度：将大对象（这个对象可能会被很多线程访问），拆成小对象，大大增加并行度，降低锁竞争。
降低了锁的竞争，偏向锁，轻量级锁成功率才会提高。最最典型的减小锁粒度的案例就是ConcurrentHashMap。
3. 锁分离：最常见的锁分离就是读写锁 ReadWriteLock，根据功能进行分离成读锁和写锁，这样读读不互斥，
读写互斥，写写互斥，即保证了线程安全，又提高了性能，
4. 锁粗化：通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短，即在使用完
公共资源后，应该立即释放锁。但是，凡事都有一个度，如果对同一个锁不停的进行请求、同步和释放，
其本身也会消耗系统宝贵的资源，反而不利于性能的优化 。
























































































































































